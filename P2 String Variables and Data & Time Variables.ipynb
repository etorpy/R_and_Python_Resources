{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPScbsDWhjjS"
   },
   "source": [
    "# Python Libraries\n",
    "\n",
    "Commonly used Python libraries:\n",
    "\n",
    "* **Numpy (np)** a library for working with arrays of data\n",
    "\n",
    "* **Pandas (pd)** provides high-performance, easy-to-use data structures and data analysis tools\n",
    "\n",
    "* **Scipy** a library of techniques for numerical and scientific computing (only import specific functions)\n",
    "\n",
    "* **Matplotlib.pyplot (plt)** plotting library for making graphs (only import the **pyplot** module)\n",
    "\n",
    "* **Seaborn (sns)** a higher-level interface to Matplotlib that can be used to simplify many graphing tasks\n",
    "\n",
    "* **Statsmodels.api (sm)** provides classes and functions for the estimation of many different statistical models\n",
    "\n",
    "* **scikit-learn** a machine learning library with many of the same statistical techiques as Statsmodels (only import specific functions) \n",
    "  \n",
    "  \n",
    "NOTE: libraries can be imported in their entirety (with an alias) or just a portion of the library can be imported.  \n",
    "* Importing a *library*: **import** numpy as np\n",
    "* Importing a *module*: **import** matplotlib.pyplot as plt\n",
    "* Importing a *function*: **from** numpy **import** arange  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonly used sample datasets\n",
    "\n",
    "Seaborn sample datasets  \n",
    "https://github.com/mwaskom/seaborn-data  \n",
    "(used as a target for the seaborn.load_dataset function)\n",
    "\n",
    "scikit-learn sample datasets (need to be conveted into datafames)  \n",
    "https://scikit-learn.org/stable/datasets/index.html#toy-datasets  \n",
    "(note: scikit-learn dataset objects have separate \"data\", \"feature_names\", and \"target\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonly used functions  \n",
    "\n",
    "* **pd.read_csv** Pandas function to read *.csv files\n",
    "* **df.describe()** produces descriptive stats on the numeric variables in a dataframe named \"df\"\n",
    "* **df.head()** shows the top of the dataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads the Boston housing data from scikit-learn and creates a Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9oG4uoyAhjjX"
   },
   "source": [
    "Pandas has a variety of functions named '`read_xxx`' for reading data in different formats.  Right now we will focus on reading '`csv`' files, which stands for comma-separated values. However the other file formats include excel, json, and sql just to name a few.\n",
    "\n",
    "There are many other options to '`read_csv`' that are very useful.  For example, you would use the option `sep='\\t'` instead of the default `sep=','` if the fields of your data file are delimited by tabs instead of commas.  See [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) for the full documentation for '`read_csv`'.\n",
    "\n",
    "\n",
    "NOTE: From this point forward, this notebook needs to be re-written\n",
    "\n",
    "### String Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fip4VOLMhjjY"
   },
   "source": [
    "The next cell shows how to call functions within an imported library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9S03bwnkhjja",
    "outputId": "f3a621eb-281b-4f96-b4a9-ca112e4f8604"
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]]) \n",
    "b = np.array([[11,12],[13,14]]) \n",
    "\n",
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljjQpFYfhjje"
   },
   "source": [
    "As you can see, we used the dot() function within the numpy library to calculate the dot product of two arrays, a and b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "auNcbdxVhjjf"
   },
   "source": [
    "# Date Functions\n",
    "\n",
    "Python stores dates and times as the number of seconds from an epoch (a point where the time starts). To find out what the epoch is, look at gmtime(0).\n",
    "\n",
    "Python Documentation: datetime — Basic date and time types  \n",
    "https://docs.python.org/3/library/datetime.html  \n",
    "(see links for specific documentation on “calendar” and “time” functions)  \n",
    "\n",
    "Python Wiki: Working with Time  \n",
    "https://wiki.python.org/moin/WorkingWithTime  \n",
    "\n",
    "Leap year problem  \n",
    "https://en.wikipedia.org/wiki/Leap_year_problem  \n",
    "(Some software programs have had problems with how they account for leap years.)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=1970, tm_mon=1, tm_mday=1, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=1, tm_isdst=0) \n",
      " time.struct_time(tm_year=2020, tm_mon=5, tm_mday=4, tm_hour=18, tm_min=55, tm_sec=37, tm_wday=0, tm_yday=125, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "import time  # imports the time module \n",
    "# NOTE: the epoch is usually Jan 1, 1970\n",
    "\n",
    "var_time1=time.gmtime(0)   # returns the epoch date\n",
    "var_time2=time.gmtime()    # returns the current date\n",
    "\n",
    "print(var_time1,\"\\n\",var_time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbGKgakihjjg"
   },
   "source": [
    "### Creating date variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXHHhj2jhjjg",
    "outputId": "af99e411-9c09-44aa-d619-553b2d2a5aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-04 13:55:49.272758\n"
     ]
    }
   ],
   "source": [
    "import datetime  # imports the datetime module\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August\n",
      "Sunday\n"
     ]
    }
   ],
   "source": [
    "import datetime  # imports the datetime module\n",
    "my_bd = datetime.datetime(1962, 8, 12)\n",
    "#print(my_bd)\n",
    "#print(my_bd.month)          # return the month number\n",
    "print(my_bd.strftime(\"%B\"))  # return the month\n",
    "print(my_bd.strftime(\"%A\"))  # returns the weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-TrO3YWShjjl"
   },
   "source": [
    "### Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMgR30w4hjjl",
    "outputId": "9a269897-78a7-4380-9634-81d2d6165c2d"
   },
   "outputs": [],
   "source": [
    "# We can view our Data Frame by calling the head() function\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwcqqpCrhjjp"
   },
   "source": [
    "The head() function simply shows the first 5 rows of our Data Frame.  If we wanted to show the entire Data Frame we would simply write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clB7ZnfOhjjq",
    "outputId": "32b34b9e-c481-4c46-b443-488ac7097c55"
   },
   "outputs": [],
   "source": [
    "# Output entire Data Frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-F1DVbu4hjju"
   },
   "source": [
    "As you can see, we have a 2-Dimensional object where each row is an independent observation of our cartwheel data.\n",
    "\n",
    "To gather more information regarding the data, we can view the column names and data types of each column with the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEdgVYnDhjjv",
    "outputId": "3c4a5edc-e29d-4665-b58c-b2e9fa125442"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIekmzj6hjkT"
   },
   "source": [
    "We can view the data types of our data frame columns with by calling .dtypes on our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVvtjY7ghjkU",
    "outputId": "4cb2e4f1-19f7-46f8-b5f4-3d1d3b779c67"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The following is from a UofM notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxzHKNfKhjkX"
   },
   "source": [
    "The output indicates we have integers, floats, and objects with our Data Frame.\n",
    "\n",
    "We may also want to observe the different unique values within a specific column, lets do this for Gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brIC2kbKhjkZ",
    "outputId": "b3c7b6f1-3c6b-4145-ff19-a3437e298212"
   },
   "outputs": [],
   "source": [
    "# List unique values in the df['Gender'] column\n",
    "df.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Js4ikCVWhjkc",
    "outputId": "4cfbdf05-044e-4c56-9430-d392a589e9ee"
   },
   "outputs": [],
   "source": [
    "# Lets explore df[\"GenderGroup] as well\n",
    "df.GenderGroup.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3pqgpifhjkf"
   },
   "source": [
    "It seems that these fields may serve the same purpose, which is to specify male vs. female. Lets check this quickly by observing only these two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Oqj-XOghjkf",
    "outputId": "a02d15e9-bd6c-4f41-aa26-10dc0d8697e4"
   },
   "outputs": [],
   "source": [
    "# Use .loc() to specify a list of mulitple column names\n",
    "df.loc[:,[\"Gender\", \"GenderGroup\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0S7vCwphjkj"
   },
   "source": [
    "From eyeballing the output, it seems to check out.  We can streamline this by utilizing the groupby() and size() functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNvUQetJhjkj",
    "outputId": "3eedb9e8-0d1a-4a1f-ff65-f7ee4a178c5e"
   },
   "outputs": [],
   "source": [
    "df.groupby(['Gender','GenderGroup']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bHLzOH2hjkn"
   },
   "source": [
    "This output indicates that we have two types of combinations. \n",
    "\n",
    "* Case 1: Gender = F & Gender Group = 1 \n",
    "* Case 2: Gender = M & GenderGroup = 2.  \n",
    "\n",
    "This validates our initial assumption that these two fields essentially portray the same information."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Introduction to Libraries and Data Management.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
